\section{Summary}
Over the past few years, tracking the spread of COVID-19 has been crucial to developing a scientific understanding the disease, which ultimately guided public health protocols aimed at controlling the spread of the disease across the world. As with any epidemic/pandemic, reported case counts wthin a defined geographic region is one of the most accessible statistics indicating the scale of the spread of a disease. However, due to testing availability, there may be many individuals in a given region that have been infected but not tested. This means that the total number of infection may be much greater than that reflected from reported case counts (cite).\\
\newline$ $
To more accuratly estimate the cumulative number of infections over a period of time, an alternative approach is to conduct population-based seroprevalence studies. To carry out a seroprevalence study for a given region on a given disease, researchers begin by obtaining a sample representative of the population. Antibody tests are then performed for the disease of interest over each individual in the sample. A positive antibody test indicates a case of infection of the tested disease. Therefore, the proportion of positive tests in the sample can be used as an estimate of the porportion of population infected with the disease over some time interval, which we call the cumulative incidence. With the estimated cumulative incidence, one can estimate the total number of infected individuals in the population. It is worth noting, however, that seroprevalence studies cannot identify previous infections whose antibodies are no longer detectable or recent infections that have yet to produce detectable antibodies. At the same time, they also do not include individuals that have died after becoming infected. As a result, a seroprevalence study as we describe it here is only informative about cumulative incidence for the average period over which antibodies are detectable, provided that the disease has a relatively low fatality rate.\\
\newline$ $
We know that COVID-19 has a relatively low fatality rate (cite). We also know that an individual starts to produce detectable antibodies after an average of 25 days since infection, and that the antibodies stay detectable for months after infection (cite). Therefore, using data from a seroprevalence study conducted within the first few months of the pandemic, we can estimate cumulative incidence over the period from the beginning of the pandemic until roughly a month prior to when the samples were taken.\\
\newline$ $
Since antibody tests are not 100\% accurate, there may be positive cases that test negative and negative cases that test positive. Therefore, one would ideally also like to adjust cumulative incidence for test-kit performance. This is typically done as follows. We begin by defining test specificity $sp$ as the proportion of noncases that test negative and test sensitivity $se$ as the proportion of actual cases that test positive. Then with the true cumulative incidence being denoted as $s$, we can model the observed prevalence (proportion of positive tests in the sample) of a given region $p$ as
\[
p = s \times se + (1-s) \times (1 - sp).
\]
To put in words, the observed prevalence can be decomposed into proportion of actual cases that correctly test positive and noncases that incorrectly test positive. Given the total sample size $n$ from a given region and the number of positive tests $x$ from the sample, it is reasonable to assume that
\[
x \given n, p \distas \distBinom(n, p).
\]
Then we can construct a bayesian model by defining a set of prior distributions on each of $s, se$, and $sp$ using distributions with a support on $[0,1]$ and viewing the above as the likelihood. (cite) applies this bayesian model to a dataset obtained from a seroprevalence study conducted in New York state between April 19 and April 28 in 2020. This dataset contains the number of positive antibody tests and the total number of tests from each of 11 regions across New York state. Full details of data can be found in (citation). Adjusting for the average time between infection and when antibodies become detectable, this dataset can be used to estimate cumulative incidences from the beginning of the pandemic until Mar 29, 2020. This is because there are 25 days between Mar 29, 2020 and the seroprevalence study midpoint April 23, 2020.\\
\newline$ $
Instead of directly applying the above Bayesian model where each region gets its own prior on cumulative incidence, (cite) remarks that it is possible that regions close to each other may share sociodemographic factors which are associated with the number of infections. As a result, (cite) groups the 11 regions into three super-regions (New York City, Westchester and Rockland Counties and Long Island, as well as rest of state), with regions from the same super-region sharing the same prior distribution on their cumulative incidences. Denoting $s_{ij}, p_{ij}, n_{ij}$ and $x_{ij}$ as the cumulative incidence, observed incidence, number of samples, and number of positive antibody tests from the $i^\text{th}$ region in the $j^\text{th}$ super-region, the final Bayesian model is defined as follows.
\[
s_{i1} &\distiid \distBeta(2.1792, 9.8208) \quad \forall i \text{ in super-region} 1 \text{ (New York City)},\\
s_{i2} &\distiid \distBeta(2.6641, 9.3359) \quad \forall i \text{ in super-region} 2 \text{ (Westchester, Rockland Counties and Long Island)},\\
s_{i3} &\distiid \distBeta(1.1930, 10.8070) \quad \forall i \text{ in super-region} 3 \text{ (rest of state)},\\
se &\distas \distBeta(205, 29)_{\{0.8, 0.95\}},\\
sp &\distas \distBeta(288, 2)_{\{0.9, 1\}},\\
p_{ij} &= s_{ij} \times se + (1-s_{ij}) \times (1 - sp),\\
x_{ij} \given n_{ij}, p_{ij} &\distind \distBinom(n_{ij}, p_{ij}).
\]
The priors for each region are chosen so that the mean of the prior matches the ratio between the cumulative case count up until March 29, 2020 and the total population of the corresponding super-region. On the other hand, the priors on test sensitivity and test specificity are based on validation studies. (cite) estimates the test specificity to be 0.9975 with a 95\% confidence interval of 0.961 and 1, and the test sensitivity to be 0.879 with a 95\% confidence interval of 0.837 and 0.921. The priors are then chosen so that means and variances of these priors match the results from the validation studies. Note that the subscripts denotes truncation to the specified regions. With the model specified, we can use Markov Chain Monte Carlo to obtain samples from the posterior distribution of regional cumulative incidences as well as test specificity and sensitivity. Given a set of regional cumulative incidences, we can estimate the cumulative incidence for each super-region or the entire state using the average over the corresponding regional cumulative incidences weighted by the proportion of population living in each region. (cite) uses the median values over $100,000$ samples as point estimates, with the equal tailed 95\% credible intervals quantifying the uncertainty about the estimates.\\
\newline$ $
(cite) compares the results from the above Bayesian model to a non-Bayesian version of the same analysis. Given a specific region (or super-region, or the entire state), with the sample proportion of positive tests being denoted $p$, we can estimate the cumulative incidence of that region by rearranging the equation that adjusts for test specificity and sensitivity. This leads to
\[
s = (p + sp - 1) / (se + sp - 1).
\]
The point estimate is obtained by plugging in the estimated test specificity and sensitivity from validation studies. To quantify the uncertainty around each point estimate, the 95\% confidence interval endpoints from validation studies are plugged into the above equation. In particular, the lowerbound on cumulative incidence can be obtained by plugging in the upper endpoint of test sensitivity and lower endpoint of test specificity, and vice versa. For the most part, the point estimates from both the Bayesian and non-Bayesian analyses are similar, but the Bayesian credible intervals are generally narrower than the interval constructed using confidence interval endpoints. In addition, while some of the intervals constructed using confidence interval endpoints contain a negative lowerbound, this does not happen to any of the credible intervals constructed. We elaborate on pros and cons of the two analyses in the following sections.