\section{Introduction}
Over the past few years, tracking the spread of COVID-19 has been crucial to developing a scientific understanding the disease, which ultimately guided public health protocols aimed at controlling the spread of the disease across the world. As with any epidemic/pandemic, reported case counts wthin a defined geographic region is one of the most accessible statistics indicating the scale of the spread of a disease. However, due to testing availability, there may be many individuals in a given region that have been infected but not tested. This means that the total number of infection may be much greater than that reflected from reported case counts \citep{byambasuren2021comparison}.\\
\newline$ $
To more accuratly estimate the cumulative number of infections over a period of time, an alternative approach is to conduct population-based seroprevalence studies. To carry out a seroprevalence study for a given region on a given disease, researchers begin by obtaining a sample representative of the population. Antibody tests are then performed for the disease of interest over each individual in the sample. A positive antibody test indicates a case of infection of the tested disease. Therefore, the proportion of positive tests in the sample can be used as an estimate of the porportion of population infected with the disease over some time interval, which we call the cumulative incidence. Given the population size of the corresponding region, one can estimate the total number of infected individuals in the population using the estimated cumulative incidence. It is worth noting, however, that seroprevalence studies cannot identify previous infections whose antibodies are no longer detectable or recent infections that have yet to produce detectable antibodies. At the same time, they also do not include individuals that have died after becoming infected. As a result, a seroprevalence study as we describe it here is only informative about cumulative incidence for the average period, prior to sample collection, over which antibodies are detectable, provided that the disease has a relatively low fatality rate.\\
\newline$ $
We know that COVID-19 has a relatively low fatality rate. In fact, it is estimated to be around $2.5$\% in the US by \cite{khafaie2020cross}. We also know that an individual starts to produce detectable antibodies after an average of 25 days since infection, and that the antibodies stay detectable for months after infection \citep{sethuraman2020interpreting,choe2021antibody}. Therefore, using data from a seroprevalence study conducted within the first few months of the COVID-19 pandemic, we can estimate cumulative incidence over the period from the beginning of the pandemic until roughly a month prior to when the samples were taken.
\subsection{Adjusting for test-kit performance}
Since antibody tests are not 100\% accurate, there may be positive cases that test negative and negative cases that test positive. Therefore, one would ideally also like to adjust cumulative incidence for test-kit performance. This is typically done as follows. We begin by defining test specificity $sp$ as the proportion of noncases that test negative and test sensitivity $se$ as the proportion of actual cases that test positive. Then with the true cumulative incidence being denoted as $s$, we can write the observed prevalence $p$, which describes the proportion of population that would test positive for antibodies to the virus that causes the disease of interest, as
\[
p = s \times se + (1-s) \times (1 - sp).
\]
To put in words, the observed prevalence can be decomposed into the proportion of actual cases that correctly test positive and noncases that incorrectly test positive. There are multiple approaches for incorporating this test-kit performance adjustment into the analysis of seroprevalence data. \cite{meyer2022adjusting} proposes a novel Bayesian model that adjusts cumulative incidence for test-kit performance. This method is then applied to a dataset from a COVID-19 seroprevalence study (based on detection of SARS-Cov-2 IgG) conducted in New York state in early 2020. We walk through the construction of this method in the following section.
\section{A Bayesian Approach to Analysis of Seroprevalence Data}
Given the total sample size $n$ from some region and the number of positive tests $x$ from the sample, we can follow the above test-kit performance adjustment and model the number of positive tests as the outcome of a Binomial distribution with the total sample size as the number of trials and observed prevalence as the probability of success, i.e.,
\[
x \given n, s, se, sp \distas \distBinom\left(n, s \times se + (1-s) \times (1 - sp)\right) = \distBinom(n, p).
\]
Using the above as the likelihood function of $s, se$ and $sp$, we can construct a Bayesian model by defining a set of prior distributions on each of $s, se$, and $sp$ using distributions whose support is on $[0,1]$. These prior distributions represent our apriori knowledge about these quantities. The prior and the likelihood together lead to a posterior distribution (conditional distribution given observed data) of $s$, which we can use to describe our belief on the cumulative incidence updated by observing the data at hand. 
\subsection{Deploying the Bayesian model}
\cite{meyer2022adjusting} applies this bayesian model to a dataset obtained from a seroprevalence study conducted in New York state between April 19 and April 28 in 2020. This dataset contains the number of positive antibody tests and the total number of tests from each of the 11 regions across New York state in the study. Full details of data can be found in \cite{rosenberg2020cumulative}. With consideration of the average time between infection and when antibodies become detectable, this dataset can be used to estimate cumulative incidences from the beginning of the pandemic until Mar 29, 2020. This is because there are 25 days between Mar 29, 2020 and the seroprevalence study midpoint April 23, 2020.\\
\newline$ $
Instead of directly applying the above Bayesian model where each region gets its own prior on cumulative incidence, \cite{meyer2022adjusting} remarks it is possible that regions close to each other geographically may share sociodemographic factors which are associated with the number of infections. As a result, \cite{meyer2022adjusting} groups the 11 regions into three super-regions (New York City, Westchester and Rockland Counties and Long Island, as well as rest of state), with regions from the same super-region sharing a common prior distribution on their cumulative incidences. Denoting $s_{ij}, p_{ij}, n_{ij}$ and $x_{ij}$ as the cumulative incidence, observed incidence, number of samples, and number of positive antibody tests from the $i^\text{th}$ region in the $j^\text{th}$ super-region, the final Bayesian model is defined as follows.
\[
s_{i1} &\distiid \distBeta(2.1792, 9.8208) \quad \forall i \text{ in super-region} 1 \text{ (New York City)},\\
s_{i2} &\distiid \distBeta(2.6641, 9.3359) \quad \forall i \text{ in super-region} 2 \text{ (Westchester, Rockland Counties and Long Island)},\\
s_{i3} &\distiid \distBeta(1.1930, 10.8070) \quad \forall i \text{ in super-region} 3 \text{ (rest of state)},\\
se &\distas \distBeta(205, 29)_{\{0.8, 0.95\}},\\
sp &\distas \distBeta(288, 2)_{\{0.9, 1\}},\\
p_{ij} &= s_{ij} \times se + (1-s_{ij}) \times (1 - sp), \quad \forall i, j\\
x_{ij} \given n_{ij}, p_{ij} &\distind \distBinom(n_{ij}, p_{ij}) \quad \forall i, j.
\]
The priors for each region are chosen so that the mean of the prior matches the ratio between the cumulative reported case count up until March 29, 2020 and the total population of the corresponding super-region. On the other hand, the priors on test sensitivity and test specificity are based on validation studies: \cite{rosenberg2020cumulative} estimates the test specificity to be $0.9975$ with a 95\% confidence interval of $[0.961, 1]$, and the test sensitivity to be $0.879$ with a 95\% confidence interval of $[0.837, 0.921]$. The priors are then chosen so that means and variances of the priors on test specificity and sensitivity to match the results from the validation studies. Note that the subscripts denote truncation to the specified regions.\\
\newline$ $
Suppose that there are $r_j$ regions in the $j^\text{th}$ super-region, we can write density of the target posterior distribution as
\[
p(S, se, sp \given X, N) = \frac{1}{Z}p(se)p(sp)\prod_{j=1}^3\prod_{i=1}^{r_j} p(s_{ij})p(x_{ij}\given sp, se, s_{ij}),
\]
where $p(\cdot)$ is the prior density corresponding to each parameter of interest, $p(\cdot \given \cdot)$ is the likelihood, and $Z$ is the normalization constant. Also note that $S$, $X$ and $N$ denote vectors containing the cumulative incidence, number of positive tests in the sample, and total sample size for each region considered in the study. With the model specified, we can use Markov Chain Monte Carlo to obtain samples from the posterior distribution of regional cumulative incidences as well as test specificity and sensitivity. Given a set of regional cumulative incidences from the posterior distribution, we can estimate the cumulative incidence for each super-region or the entire state using the average over the corresponding regional cumulative incidences weighted by the proportion of population living in each region. \cite{meyer2022adjusting} uses the median values over $100,000$ posterior samples as point estimates for each parameter of interest. At the same time, equal tailed 95\% credible intervals, which cover 95\% of the area under the corresponding posterior densities, are used to quantify the uncertainty about the estimates.
\subsection{Related frequentist approaches}
\cite{meyer2022adjusting} compares the results from the above Bayesian model to a non-Bayesian version of the same analysis. In the non-Bayesian version of the analysis, given a specific region (or super-region, or the entire state), with the sample proportion of positive tests being denoted $\hat{p}$, we can estimate the cumulative incidence of that region by rearranging the equation that adjusts for test specificity and sensitivity.
\[
\hat{p} = s \times se + (1-s) \times (1 - sp) \implies s = (\hat{p} + sp - 1) / (se + sp - 1).
\]
Note that here the sample proportion of positive tests plays the same role as observed prevalence in the Bayesian version of the analysis. The point estimate of the cumulative incidence is obtained by plugging in the estimated test specificity and sensitivity values from the validation studies. To quantify the uncertainty around each point estimate in terms of test-kit performance, \cite{meyer2022adjusting} constructs an iterval using the 95\% confidence interval endpoints from the validation studies. Let $\hat{se}, \hat{sp}$ denote the point estimates for test sensitivity and specificity from the validation studies, with the corresponding 95\% confidence intervals being $[se_l, se_u]$ and $[sp_l, sp_u]$. The uncertainty interval associated with $s$ can be written as
\[
[(\hat{p} + sp_l - 1) / (se_u + sp_l - 1), \quad &(\hat{p} + sp_u - 1) / (se_l + sp_u - 1)].
\] 
In particular, the lowerbound of this above interval is obtained by plugging in the lower endpoint of test specificity and upper endpoint of test sensitivity, and vice versa. It is worth noting, however, that this interval is not a 95\% confidence interval around the true cumulative incidence of the corresponding region.\\
\newline$ $
Alternatively, \cite{rosenberg2020cumulative} takes on a different approach quantifying the uncertainty around each estimated cumulative incidence. The procedure can be summarized as follows. Given the number of positive tests as well as total sample size in a region, we can construct a 95\% confidence interval on the observed prevalence for that given region. We denote this interval $[p_l, p_u]$. To incorporate the uncertainty of test-kit performance, we can construct the following three sets of 95\% confidence intervals on the cumulative incidence
\[
[(p_l + \hat{sp} - 1) / (\hat{se} + \hat{sp} - 1), \quad &(p_u + \hat{sp} - 1) / (\hat{se} + \hat{sp} - 1)],\\
[(p_l + sp_l - 1) / (se_u + sp_l - 1), \quad &(p_u + sp_l - 1) / (se_u + sp_l - 1)],\\
[(p_l + sp_u - 1) / (se_l + sp_u - 1), \quad &(p_u + sp_u - 1) / (se_l + sp_u - 1)].
\]
In the above three intervals, the first one corresponds to the average test-kit performance obtained from the validation studies, the second interval corresponds to the worst case of combined test-kit performance, and the third interval corresponds to the best case of combined test-kit performance.\\
\newline$ $
Comparing the results from both studies, we can see that the point estimates from both the Bayesian and non-Bayesian analyses are relatively similar, but the Bayesian credible intervals are generally narrower than the intervals constructed using confidence interval endpoints. In addition, while some of the intervals constructed using confidence interval endpoints contain a negative lowerbound, this does not happen to any of the credible intervals constructed. A full comparison can be found in \cite{meyer2022adjusting}. In the following section, we discuss the advantages and disadvantages of the Bayesian seroprevalence analysis.